{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Regime Prediction - Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from model import MarketRegimeTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Data parameters\nDATA_DIR = 'data/training'\nLOOKBACK_WINDOW = 256  # ~1 year of trading data\n\n# Training parameters\nBATCH_SIZE = 160\nNUM_EPOCHS = 80\nLEARNING_RATE = 1e-4\nNUM_WORKERS = 8\n\n# Loss weights\nCLASS_WEIGHT = 1.0\nDURATION_WEIGHT_START = 0.05  # Gradually increase from this\nDURATION_WEIGHT_END = 0.4     # To this value\n\n# Model parameters\nN_FEATURES = 7  # OHLCV + RSI + BB\nD_MODEL = 256\nN_HEAD = 8\nNUM_FEATURE_LAYERS = 4\nNUM_AGGREGATE_LAYERS = 3\nDIM_FEEDFORWARD = 1024\nDROPOUT = 0.1\nNUM_CLASSES = 3  # bull, flat, bear\n\n# Scheduler parameters\nWARMUP_EPOCHS = 10\n\n# Device\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3090\n",
      "Memory Usage:\n",
      "  Allocated: 0.0 GB\n",
      "  Cached: 0.0 GB\n",
      "  Total VRAM: 24.0 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "if DEVICE.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory Usage:\")\n",
    "    print(f\"  Allocated: {round(torch.cuda.memory_allocated(0)/1024**3,1)} GB\")\n",
    "    print(f\"  Cached: {round(torch.cuda.memory_reserved(0)/1024**3,1)} GB\")\n",
    "    print(f\"  Total VRAM: {round(torch.cuda.get_device_properties(0).total_memory/1024**3,1)} GB\")\n",
    "    \n",
    "    # Enable cuDNN optimizations\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class MultiFileMarketRegimeDataset(Dataset):\n    def __init__(self, data_dir, subset='train', lookback_window=256):\n        \"\"\"\n        Load dataset from multiple .npz files without loading all data into memory\n        Args:\n            data_dir: Base directory containing train/val subdirectories\n            subset: 'train' or 'val'\n            lookback_window: The lookback window size (for directory naming)\n        \"\"\"\n        self.data_dir = os.path.join(data_dir, subset, f'n{lookback_window}')\n        \n        # Find all .npz files\n        self.files = sorted([f for f in os.listdir(self.data_dir) if f.endswith('.npz')])\n        if not self.files:\n            raise ValueError(f\"No .npz files found in {self.data_dir}\")\n        \n        # Build index mapping (file_idx, sample_idx) for each global index\n        self.index_map = []\n        self.file_lengths = []\n        self.cumulative_lengths = [0]\n        \n        print(f\"Indexing {len(self.files)} files from {subset} set...\")\n        for file_idx, file in enumerate(self.files):\n            filepath = os.path.join(self.data_dir, file)\n            with np.load(filepath) as data:\n                file_length = len(data['X'])\n                self.file_lengths.append(file_length)\n                self.cumulative_lengths.append(self.cumulative_lengths[-1] + file_length)\n                \n                # Add mappings for this file\n                for sample_idx in range(file_length):\n                    self.index_map.append((file_idx, sample_idx))\n        \n        self.total_samples = self.cumulative_lengths[-1]\n        print(f\"Indexed {self.total_samples} samples from {subset} set\")\n        \n        # Cache for recently accessed files\n        self.cache = {}\n        self.cache_size = 5  # Keep up to 5 files in memory\n        self.access_order = []\n        \n    def _load_file(self, file_idx):\n        \"\"\"Load a file into cache if not already loaded\"\"\"\n        if file_idx not in self.cache:\n            # Remove oldest file if cache is full\n            if len(self.cache) >= self.cache_size:\n                oldest_idx = self.access_order.pop(0)\n                del self.cache[oldest_idx]\n            \n            # Load new file\n            filepath = os.path.join(self.data_dir, self.files[file_idx])\n            self.cache[file_idx] = np.load(filepath)\n            self.access_order.append(file_idx)\n        else:\n            # Move to end of access order\n            self.access_order.remove(file_idx)\n            self.access_order.append(file_idx)\n        \n        return self.cache[file_idx]\n    \n    def __len__(self):\n        return self.total_samples\n    \n    def __getitem__(self, idx):\n        if idx >= self.total_samples:\n            raise IndexError(f\"Index {idx} out of range for dataset with {self.total_samples} samples\")\n        \n        # Get file and sample indices\n        file_idx, sample_idx = self.index_map[idx]\n        \n        # Load file data\n        data = self._load_file(file_idx)\n        \n        # Return the specific sample\n        X = data['X'][sample_idx].astype(np.float32)\n        y_class = data['y_class'][sample_idx].astype(np.long)\n        y_duration = data['y_duration'][sample_idx].astype(np.float32)\n        \n        return X, y_class, y_duration"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def create_data_loaders(data_dir, batch_size, num_workers, lookback_window):\n    \"\"\"Create training and validation data loaders using multi-file dataset\"\"\"\n    # Check if directories exist\n    train_dir = os.path.join(data_dir, 'train', f'n{lookback_window}')\n    val_dir = os.path.join(data_dir, 'val', f'n{lookback_window}')\n    \n    if os.path.exists(train_dir) and os.path.exists(val_dir):\n        # Load pre-separated datasets\n        print(\"Loading pre-separated train/validation sets from multiple files...\")\n        train_dataset = MultiFileMarketRegimeDataset(data_dir, subset='train', lookback_window=lookback_window)\n        val_dataset = MultiFileMarketRegimeDataset(data_dir, subset='val', lookback_window=lookback_window)\n        \n        train_loader = DataLoader(\n            train_dataset, \n            batch_size=batch_size, \n            shuffle=True,\n            num_workers=num_workers,\n            pin_memory=True,\n            persistent_workers=True if num_workers > 0 else False\n        )\n        \n        val_loader = DataLoader(\n            val_dataset, \n            batch_size=batch_size, \n            shuffle=False,\n            num_workers=num_workers,\n            pin_memory=True,\n            persistent_workers=True if num_workers > 0 else False\n        )\n        \n        return train_loader, val_loader, len(train_dataset), len(val_dataset)\n    \n    else:\n        raise ValueError(f\"Data directories not found. Please run generate_training_data_v4.py first.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def load_class_weights(data_dir, lookback_window, device):\n    \"\"\"Load class weights from training data statistics\"\"\"\n    try:\n        # Try to load from manifest file first\n        manifest_path = os.path.join(data_dir, 'train', f'n{lookback_window}', 'manifest.json')\n        if os.path.exists(manifest_path):\n            with open(manifest_path, 'r') as f:\n                manifest = json.load(f)\n                if 'class_distribution' in manifest:\n                    class_dist = manifest['class_distribution']\n                    total = sum(class_dist.values())\n                    class_pcts = {\n                        'bull': class_dist['bull'] / total * 100,\n                        'flat': class_dist['flat'] / total * 100,\n                        'bear': class_dist['bear'] / total * 100\n                    }\n        else:\n            # Calculate from data if manifest doesn't exist\n            print(\"Calculating class weights from training data...\")\n            train_dir = os.path.join(data_dir, 'train', f'n{lookback_window}')\n            class_counts = {'bull': 0, 'flat': 0, 'bear': 0}\n            \n            for file in os.listdir(train_dir):\n                if file.endswith('.npz'):\n                    filepath = os.path.join(train_dir, file)\n                    with np.load(filepath) as data:\n                        y_class = data['y_class']\n                        class_counts['bull'] += np.sum(y_class == 0)\n                        class_counts['flat'] += np.sum(y_class == 1)\n                        class_counts['bear'] += np.sum(y_class == 2)\n            \n            total = sum(class_counts.values())\n            class_pcts = {k: v / total * 100 for k, v in class_counts.items()}\n        \n        # Calculate weights inversely proportional to class frequency\n        weights = torch.tensor([\n            100.0 / class_pcts['bull'],\n            100.0 / class_pcts['flat'],\n            100.0 / class_pcts['bear']\n        ]).to(device)\n        \n        # Normalize weights\n        weights = weights / weights.mean()\n        \n        print(f\"Loaded class weights from training data:\")\n        print(f\"  Bull: {weights[0]:.3f} ({class_pcts['bull']:.1f}% of data)\")\n        print(f\"  Flat: {weights[1]:.3f} ({class_pcts['flat']:.1f}% of data)\")\n        print(f\"  Bear: {weights[2]:.3f} ({class_pcts['bear']:.1f}% of data)\")\n        \n        return weights\n    except Exception as e:\n        # Default weights if calculation fails\n        print(f\"Error calculating class weights: {e}\")\n        print(\"Using default class weights\")\n        return torch.tensor([0.760, 1.294, 0.991]).to(device)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion_class, criterion_duration, optimizer, device, class_weight, duration_weight):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, target_class, target_duration) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target_class = target_class.to(device)\n",
    "        target_duration = target_duration.to(device).unsqueeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        class_logits, duration_pred = model(data)\n",
    "        \n",
    "        loss_class = criterion_class(class_logits, target_class)\n",
    "        loss_duration = criterion_duration(duration_pred, target_duration)\n",
    "        \n",
    "        loss = class_weight * loss_class + duration_weight * loss_duration\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = class_logits.max(1)\n",
    "        total += target_class.size(0)\n",
    "        correct += predicted.eq(target_class).sum().item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'  Batch [{batch_idx}/{len(train_loader)}] Loss: {loss.item():.4f} '\n",
    "                  f'(Class: {loss_class.item():.4f}, Duration: {loss_duration.item():.4f})')\n",
    "    \n",
    "    accuracy = 100. * correct / total\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion_class, criterion_duration, device, class_weight, duration_weight):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = {0: 0, 1: 0, 2: 0}\n",
    "    class_total = {0: 0, 1: 0, 2: 0}\n",
    "    duration_mse = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target_class, target_duration in val_loader:\n",
    "            data = data.to(device)\n",
    "            target_class = target_class.to(device)\n",
    "            target_duration = target_duration.to(device).unsqueeze(1)\n",
    "            \n",
    "            class_logits, duration_pred = model(data)\n",
    "            \n",
    "            loss_class = criterion_class(class_logits, target_class)\n",
    "            loss_duration = criterion_duration(duration_pred, target_duration)\n",
    "            loss = class_weight * loss_class + duration_weight * loss_duration\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = class_logits.max(1)\n",
    "            total += target_class.size(0)\n",
    "            correct += predicted.eq(target_class).sum().item()\n",
    "            \n",
    "            # Track duration MSE\n",
    "            duration_mse += ((duration_pred - target_duration) ** 2).sum().item()\n",
    "            \n",
    "            for i in range(target_class.size(0)):\n",
    "                label = target_class[i].item()\n",
    "                class_total[label] += 1\n",
    "                if predicted[i] == label:\n",
    "                    class_correct[label] += 1\n",
    "    \n",
    "    accuracy = 100. * correct / total\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    avg_duration_mse = duration_mse / total\n",
    "    \n",
    "    class_accuracies = {\n",
    "        'bull': 100. * class_correct[0] / class_total[0] if class_total[0] > 0 else 0,\n",
    "        'flat': 100. * class_correct[1] / class_total[1] if class_total[1] > 0 else 0,\n",
    "        'bear': 100. * class_correct[2] / class_total[2] if class_total[2] > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return avg_loss, accuracy, class_accuracies, avg_duration_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"Loading data...\")\ntrain_loader, val_loader, train_size, val_size = create_data_loaders(\n    DATA_DIR, \n    BATCH_SIZE,\n    NUM_WORKERS,\n    LOOKBACK_WINDOW\n)\nprint(f\"Training samples: {train_size}, Validation samples: {val_size}\")\nprint(f\"NOTE: Validation set contains S&P 500 correlated instruments only\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load class weights\n",
    "class_weights = load_class_weights(DATA_DIR, LOOKBACK_WINDOW, DEVICE)\n",
    "\n",
    "# Initialize model\n",
    "model = MarketRegimeTransformer(\n",
    "    lookback_window=LOOKBACK_WINDOW-1,  # -1 because of pct_change\n",
    "    n_features=N_FEATURES,\n",
    "    d_model=D_MODEL,\n",
    "    nhead=N_HEAD,\n",
    "    num_feature_layers=NUM_FEATURE_LAYERS,\n",
    "    num_aggregate_layers=NUM_AGGREGATE_LAYERS,\n",
    "    dim_feedforward=DIM_FEEDFORWARD,\n",
    "    dropout=DROPOUT,\n",
    "    num_classes=NUM_CLASSES\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "criterion_class = nn.CrossEntropyLoss(weight=class_weights)\n",
    "criterion_duration = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "\n",
    "# Learning rate schedulers\n",
    "scheduler1 = optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1, total_iters=WARMUP_EPOCHS)\n",
    "scheduler2 = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS-WARMUP_EPOCHS)\n",
    "scheduler = optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2], milestones=[WARMUP_EPOCHS])\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs('checkpoints', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'val_duration_mse': [],\n",
    "    'learning_rate': [],\n",
    "    'duration_weight': []\n",
    "}\n",
    "\n",
    "best_val_accuracy = 0\n",
    "best_balanced_accuracy = 0\n",
    "best_duration_mse = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Gradually increase duration weight\n",
    "    progress = epoch / NUM_EPOCHS\n",
    "    duration_weight = DURATION_WEIGHT_START + (DURATION_WEIGHT_END - DURATION_WEIGHT_START) * progress\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(f\"Duration weight: {duration_weight:.3f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, criterion_class, criterion_duration, \n",
    "        optimizer, DEVICE, CLASS_WEIGHT, duration_weight\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, class_accuracies, val_duration_mse = validate(\n",
    "        model, val_loader, criterion_class, criterion_duration, \n",
    "        DEVICE, CLASS_WEIGHT, duration_weight\n",
    "    )\n",
    "    \n",
    "    # Step scheduler\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    print(f\"Val Duration MSE: {val_duration_mse:.4f} (RMSE: {np.sqrt(val_duration_mse):.4f})\")\n",
    "    print(f\"Class Accuracies - Bull: {class_accuracies['bull']:.2f}%, \"\n",
    "          f\"Flat: {class_accuracies['flat']:.2f}%, Bear: {class_accuracies['bear']:.2f}%\")\n",
    "    print(f\"Learning Rate: {current_lr:.2e}\")\n",
    "    \n",
    "    if DEVICE.type == 'cuda':\n",
    "        print(f\"GPU Memory: {round(torch.cuda.memory_allocated(0)/1024**3,2)} GB allocated\")\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_duration_mse'].append(val_duration_mse)\n",
    "    history['learning_rate'].append(current_lr)\n",
    "    history['duration_weight'].append(duration_weight)\n",
    "    \n",
    "    # Calculate balanced accuracy\n",
    "    balanced_accuracy = (class_accuracies['bull'] + class_accuracies['flat'] + class_accuracies['bear']) / 3\n",
    "    \n",
    "    # Save best model based on multiple criteria\n",
    "    save_model = False\n",
    "    save_reason = \"\"\n",
    "    \n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        save_model = True\n",
    "        save_reason = \"best overall accuracy\"\n",
    "    \n",
    "    if balanced_accuracy > best_balanced_accuracy and val_duration_mse < 15:\n",
    "        best_balanced_accuracy = balanced_accuracy\n",
    "        save_model = True\n",
    "        save_reason = \"best balanced accuracy\"\n",
    "    \n",
    "    if val_duration_mse < best_duration_mse and val_acc > 65:\n",
    "        best_duration_mse = val_duration_mse\n",
    "        save_model = True\n",
    "        save_reason = \"best duration MSE\"\n",
    "    \n",
    "    if save_model:\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_acc': val_acc,\n",
    "            'val_duration_mse': val_duration_mse,\n",
    "            'class_accuracies': class_accuracies,\n",
    "            'balanced_accuracy': balanced_accuracy,\n",
    "            'duration_weight': duration_weight,\n",
    "            'lookback_window': LOOKBACK_WINDOW\n",
    "        }, 'checkpoints/best_model.pth')\n",
    "        print(f\"  -> New best model saved! ({save_reason})\")\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Best validation accuracy: {best_val_accuracy:.2f}%\")\n",
    "print(f\"Best balanced accuracy: {best_balanced_accuracy:.2f}%\")\n",
    "print(f\"Best duration MSE: {best_duration_mse:.4f} (RMSE: {np.sqrt(best_duration_mse):.4f})\")\n",
    "print(f\"Best model saved at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss')\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(history['train_acc'], label='Train Accuracy')\n",
    "axes[0, 1].plot(history['val_acc'], label='Val Accuracy')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].set_title('Training and Validation Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Duration MSE\n",
    "axes[1, 0].plot(history['val_duration_mse'], label='Val Duration MSE', color='green')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('MSE')\n",
    "axes[1, 0].set_title('Validation Duration MSE')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Learning Rate and Duration Weight\n",
    "ax1 = axes[1, 1]\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(history['learning_rate'], label='Learning Rate', color='blue')\n",
    "ax2.plot(history['duration_weight'], label='Duration Weight', color='red')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Learning Rate', color='blue')\n",
    "ax2.set_ylabel('Duration Weight', color='red')\n",
    "ax1.set_title('Learning Rate and Duration Weight Schedule')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "ax1.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Best Model for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load('checkpoints/best_model.pth', map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch'] + 1}\")\n",
    "print(f\"Best model metrics:\")\n",
    "print(f\"  Validation Accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "print(f\"  Validation Loss: {checkpoint['val_loss']:.4f}\")\n",
    "print(f\"  Duration MSE: {checkpoint['val_duration_mse']:.4f}\")\n",
    "print(f\"  Balanced Accuracy: {checkpoint['balanced_accuracy']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run final validation\n",
    "val_loss, val_acc, class_accuracies, val_duration_mse = validate(\n",
    "    model, val_loader, criterion_class, criterion_duration, \n",
    "    DEVICE, CLASS_WEIGHT, checkpoint['duration_weight']\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Validation Performance:\")\n",
    "print(f\"Overall Accuracy: {val_acc:.2f}%\")\n",
    "print(f\"\\nPer-Class Accuracy:\")\n",
    "print(f\"  Bull: {class_accuracies['bull']:.2f}%\")\n",
    "print(f\"  Flat: {class_accuracies['flat']:.2f}%\")\n",
    "print(f\"  Bear: {class_accuracies['bear']:.2f}%\")\n",
    "print(f\"\\nDuration Prediction:\")\n",
    "print(f\"  MSE: {val_duration_mse:.4f}\")\n",
    "print(f\"  RMSE: {np.sqrt(val_duration_mse):.4f} (≈ {np.sqrt(val_duration_mse) / 0.545:.1f} days error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training summary\n",
    "summary = {\n",
    "    'config': {\n",
    "        'lookback_window': LOOKBACK_WINDOW,\n",
    "        'n_features': N_FEATURES,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'num_epochs': NUM_EPOCHS,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'model_params': sum(p.numel() for p in model.parameters())\n",
    "    },\n",
    "    'best_results': {\n",
    "        'epoch': best_epoch,\n",
    "        'val_accuracy': best_val_accuracy,\n",
    "        'balanced_accuracy': best_balanced_accuracy,\n",
    "        'duration_mse': best_duration_mse,\n",
    "        'duration_rmse': np.sqrt(best_duration_mse)\n",
    "    },\n",
    "    'final_performance': {\n",
    "        'overall_accuracy': val_acc,\n",
    "        'class_accuracies': class_accuracies,\n",
    "        'duration_mse': val_duration_mse\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('training_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\nTraining summary saved to training_summary.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}